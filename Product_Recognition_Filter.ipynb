{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "BQbCa678FtmV",
        "outputId": "54acadba-44aa-4cd1-dec8-ca34db3d2339"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the DeepLabv3+ model\n",
        "model = torch.hub.load('pytorch/vision:v0.9.0', 'deeplabv3_resnet101', pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Define a function to preprocess the image\n",
        "def preprocess_image(image_path):\n",
        "    input_image = Image.open(image_path)\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    input_tensor = preprocess(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0)\n",
        "    return input_batch\n",
        "\n",
        "# Define a function to perform inference and get the predicted class labels\n",
        "def get_predicted_labels(input_batch):\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)['out'][0]\n",
        "    output_predictions = output.argmax(0)\n",
        "    return output_predictions.numpy()\n",
        "\n",
        "# Define a function to map class labels to product categories\n",
        "def map_labels_to_categories(label_map):\n",
        "    # Define your mapping of class labels to product categories\n",
        "    # For example: {0: 'background', 1: 'shoe', 2: 'bottle', 3: 'chair', ...}\n",
        "    label_to_category = {\n",
        "    0: 'background',\n",
        "    1: 'Shoe',        # Subcategory for Shoe\n",
        "    2: 'Sneaker',     # Subcategory for Sneaker\n",
        "    3: 'Sandal',      # Subcategory for Sandal\n",
        "    4: 'Hat',         # Subcategory for Hat\n",
        "    5: 'Cap',         # Subcategory for Cap\n",
        "    6: 'Sunglasses',  # Subcategory for Sunglasses\n",
        "    7: 'Headphones',  # Subcategory for Headphones\n",
        "    8: 'Perfume',     # Subcategory for Perfume\n",
        "    9: 'Wristwatch',  # Subcategory for Wristwatch\n",
        "    10: 'Glass',      # Subcategory for Glass\n",
        "    11: 'Bag',        # Subcategory for Bag\n",
        "    12: 'Handbag',    # Subcategory for Handbag\n",
        "    13: 'Suitcase',   # Subcategory for Suitcase\n",
        "    14: 'Bottle',     # Subcategory for Bottle\n",
        "    15: 'Cup',        # Subcategory for Cup\n",
        "    16: 'Water Bottle',  # Subcategory for Water Bottle\n",
        "    17: 'Can',        # Subcategory for Can\n",
        "    18: 'Jar',        # Subcategory for Jar\n",
        "    19: 'Vase',       # Subcategory for Vase\n",
        "    20: 'Chair',      # Subcategory for Chair\n",
        "    21: 'Office Chair',  # Subcategory for Office Chair\n",
        "    22: 'Couch',      # Subcategory for Couch\n",
        "    }\n",
        "\n",
        "    # Map the class labels to product categories\n",
        "    category_map = np.vectorize(label_to_category.get)(label_map)\n",
        "    return category_map\n",
        "\n",
        "# Define a function to apply the product recognition filter\n",
        "def apply_product_recognition(image_path):\n",
        "    input_batch = preprocess_image(image_path)\n",
        "    label_map = get_predicted_labels(input_batch)\n",
        "    category_map = map_labels_to_categories(label_map)\n",
        "    return category_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['background' 'background' 'background' ... 'background' 'background'\n",
            "  'background']\n",
            " ['background' 'background' 'background' ... 'background' 'background'\n",
            "  'background']\n",
            " ['background' 'background' 'background' ... 'background' 'background'\n",
            "  'background']\n",
            " ...\n",
            " ['background' 'background' 'background' ... 'background' 'background'\n",
            "  'background']\n",
            " ['background' 'background' 'background' ... 'background' 'background'\n",
            "  'background']\n",
            " ['background' 'background' 'background' ... 'background' 'background'\n",
            "  'background']]\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "image_path = 'Custom_Datatset/Chair/Chair_3.jpg'\n",
        "product_categories = apply_product_recognition(image_path)\n",
        "print(product_categories)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/root/anaconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "----------\n",
            " Loss: 0.1915 Acc: 0.9396\n",
            "Epoch 2/100\n",
            "----------\n",
            " Loss: 0.1446 Acc: 0.9480\n",
            "Epoch 3/100\n",
            "----------\n",
            " Loss: 0.1166 Acc: 0.9589\n",
            "Epoch 4/100\n",
            "----------\n",
            " Loss: 0.0940 Acc: 0.9706\n",
            "Epoch 5/100\n",
            "----------\n",
            " Loss: 0.0782 Acc: 0.9757\n",
            "Epoch 6/100\n",
            "----------\n",
            " Loss: 0.0750 Acc: 0.9748\n",
            "Epoch 7/100\n",
            "----------\n",
            " Loss: 0.0664 Acc: 0.9790\n",
            "Epoch 8/100\n",
            "----------\n",
            " Loss: 0.0640 Acc: 0.9732\n",
            "Epoch 9/100\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import classification_report\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Define path to your dataset\n",
        "data_dir = 'Custom_Datatset'\n",
        "\n",
        "# List all subdirectories (categories)\n",
        "categories = os.listdir(data_dir)\n",
        "\n",
        "# Create a list to hold (image_path, category_label) tuples\n",
        "all_images = []\n",
        "\n",
        "# Loop through each category and collect image paths\n",
        "for label, category in enumerate(categories):\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    for image_file in os.listdir(category_path):\n",
        "        image_path = os.path.join(category_path, image_file)\n",
        "        all_images.append((image_path, label))\n",
        "\n",
        "# Shuffle the list of (image_path, category_label) tuples\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Define the dataset size and split ratio\n",
        "dataset_size = len(all_images)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images = all_images[:train_size]\n",
        "test_images = all_images[train_size:]\n",
        "\n",
        "# Define transformations for data preprocessing\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ColorJitter(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = [(transforms.ToTensor()(Image.open(img)), label) for img, label in train_images]\n",
        "test_dataset = [(transforms.ToTensor()(Image.open(img)), label) for img, label in test_images]\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_dataset, batch_size=64, shuffle=True),\n",
        "    'test': DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "}\n",
        "\n",
        "# Define label_to_category mapping (same as before)\n",
        "label_to_category = {\n",
        "    0: 'Shoe',\n",
        "    1: 'Sneaker',\n",
        "    2: 'Sandal',\n",
        "    3: 'Hat',\n",
        "    4: 'Cap',\n",
        "    5: 'Sunglasses',\n",
        "    6: 'Headphones',\n",
        "    7: 'Perfume',\n",
        "    8: 'Wristwatch',\n",
        "    9: 'Glass',\n",
        "    10: 'Bag',\n",
        "    11: 'Handbag',\n",
        "    12: 'Suitcase',\n",
        "    13: 'Bottle',\n",
        "    14: 'Cup',\n",
        "    15: 'Water Bottle',\n",
        "    16: 'Can',\n",
        "    17: 'Jar',\n",
        "    18: 'Vase',\n",
        "    19: 'Chair',\n",
        "    20: 'Office Chair',\n",
        "    21: 'Couch',\n",
        "    22: 'Baggage',\n",
        "    23: 'Car',\n",
        "    24: 'Toy'\n",
        "}\n",
        "\n",
        "\n",
        "# Continue with model training, evaluation, and printing classification reports as before\n",
        "\n",
        "# Load pre-trained ResNet model\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(label_to_category))\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / train_size\n",
        "        epoch_acc = running_corrects.double() / train_size\n",
        "\n",
        "        print(f' Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model.load_state_dict(torch.load('resnet18_finetuned.pth'))\n",
        "model = train_model(model, criterion, optimizer, num_epochs=9)\n",
        "torch.save(model.state_dict(), 'resnet18_finetuned2.pth')\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return all_labels, all_preds\n",
        "\n",
        "# Evaluate on training set\n",
        "train_labels, train_preds = evaluate_model(model, dataloaders['train'])\n",
        "print('Classification Report on Training Set:')\n",
        "print(classification_report(train_labels, train_preds, target_names=label_to_category.values()))\n",
        "\n",
        "# Evaluate on testing set\n",
        "test_labels, test_preds = evaluate_model(model, dataloaders['test'])\n",
        "print('Classification Report on Testing Set:')\n",
        "print(classification_report(test_labels, test_preds, target_names=label_to_category.values()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up PyTorch plugin \"bias_act_plugin\"... "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed!\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Error building extension 'bias_act_plugin': [1/3] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/TH -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/THC -isystem /root/anaconda3/envs/stylegan3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' --use_fast_math --allow-unsupported-compiler -std=c++17 -c /root/.cache/torch_extensions/py39_cu121/bias_act_plugin/3cb576a0039689487cfba59279dd6d46-nvidia-geforce-rtx-4080-laptop-gpu/bias_act.cu -o bias_act.cuda.o \n\u001b[31mFAILED: \u001b[0mbias_act.cuda.o \n/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/TH -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/THC -isystem /root/anaconda3/envs/stylegan3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' --use_fast_math --allow-unsupported-compiler -std=c++17 -c /root/.cache/torch_extensions/py39_cu121/bias_act_plugin/3cb576a0039689487cfba59279dd6d46-nvidia-geforce-rtx-4080-laptop-gpu/bias_act.cu -o bias_act.cuda.o \nnvcc fatal   : Unsupported gpu architecture 'compute_89'\n[2/3] c++ -MMD -MF bias_act.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/TH -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/THC -isystem /root/anaconda3/envs/stylegan3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py39_cu121/bias_act_plugin/3cb576a0039689487cfba59279dd6d46-nvidia-geforce-rtx-4080-laptop-gpu/bias_act.cpp -o bias_act.o \nninja: build stopped: subcommand failed.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:2107\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2106\u001b[0m     stdout_fileno \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2107\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstdout_fileno\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2113\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2115\u001b[0m     \u001b[38;5;66;03m# Python 2 and 3 compatible way of getting the error object.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enhanced_images\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Generate enhanced images\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m enhanced_images \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_enhanced_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolated_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Save generated images to disk\u001b[39;00m\n\u001b[1;32m     96\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnhanced_Images\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "Cell \u001b[0;32mIn[1], line 86\u001b[0m, in \u001b[0;36mgenerate_enhanced_images\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     85\u001b[0m     stylegan_latent \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(feature[:\u001b[38;5;241m512\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()  \u001b[38;5;66;03m# Ensure the latent vector is in the correct format\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstylegan_latent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Generate image\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     img \u001b[38;5;241m=\u001b[39m (img\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m  \u001b[38;5;66;03m# Convert to [0, 255] range\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)  \u001b[38;5;66;03m# Convert to HWC format and numpy array\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m<string>:511\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, z, c, truncation_psi, truncation_cutoff, update_emas, **synthesis_kwargs)\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m<string>:151\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, z, c, truncation_psi, truncation_cutoff, update_emas)\u001b[0m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m<string>:100\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n",
            "File \u001b[0;32m~/stylegan3/torch_utils/ops/bias_act.py:84\u001b[0m, in \u001b[0;36mbias_act\u001b[0;34m(x, b, dim, act, alpha, gain, clamp, impl)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impl \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _bias_act_cuda(dim\u001b[38;5;241m=\u001b[39mdim, act\u001b[38;5;241m=\u001b[39mact, alpha\u001b[38;5;241m=\u001b[39malpha, gain\u001b[38;5;241m=\u001b[39mgain, clamp\u001b[38;5;241m=\u001b[39mclamp)\u001b[38;5;241m.\u001b[39mapply(x, b)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bias_act_ref(x\u001b[38;5;241m=\u001b[39mx, b\u001b[38;5;241m=\u001b[39mb, dim\u001b[38;5;241m=\u001b[39mdim, act\u001b[38;5;241m=\u001b[39mact, alpha\u001b[38;5;241m=\u001b[39malpha, gain\u001b[38;5;241m=\u001b[39mgain, clamp\u001b[38;5;241m=\u001b[39mclamp)\n",
            "File \u001b[0;32m~/stylegan3/torch_utils/ops/bias_act.py:41\u001b[0m, in \u001b[0;36m_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _plugin\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _plugin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     _plugin \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_plugin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act_plugin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act.cpp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act.cu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbias_act.h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--use_fast_math\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--allow-unsupported-compiler\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/stylegan3/torch_utils/custom_ops.py:136\u001b[0m, in \u001b[0;36mget_plugin\u001b[0;34m(module_name, sources, headers, source_dir, **build_kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Compile.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     cached_sources \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cached_build_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(fname)) \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m sources]\n\u001b[0;32m--> 136\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpp_extension\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_build_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_build\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcached_sources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbuild_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcpp_extension\u001b[38;5;241m.\u001b[39mload(name\u001b[38;5;241m=\u001b[39mmodule_name, verbose\u001b[38;5;241m=\u001b[39mverbose_build, sources\u001b[38;5;241m=\u001b[39msources, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbuild_kwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1309\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[1;32m   1218\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   1219\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1227\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1228\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;124;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1719\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                 hipified_sources\u001b[38;5;241m.\u001b[39madd(hipify_result[s_abs]\u001b[38;5;241m.\u001b[39mhipified_path \u001b[38;5;28;01mif\u001b[39;00m s_abs \u001b[38;5;129;01min\u001b[39;00m hipify_result \u001b[38;5;28;01melse\u001b[39;00m s_abs)\n\u001b[1;32m   1717\u001b[0m             sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hipified_sources)\n\u001b[0;32m-> 1719\u001b[0m         \u001b[43m_write_ninja_file_and_build_library\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     baton\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1832\u001b[0m, in \u001b[0;36m_write_ninja_file_and_build_library\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_standalone)\u001b[0m\n\u001b[1;32m   1830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuilding extension module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 1832\u001b[0m \u001b[43m_run_ninja_build\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError building extension \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/utils/cpp_extension.py:2123\u001b[0m, in \u001b[0;36m_run_ninja_build\u001b[0;34m(build_directory, verbose, error_prefix)\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(error, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m error\u001b[38;5;241m.\u001b[39moutput:  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   2122\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;241m*\u001b[39mSUBPROCESS_DECODE_ARGS)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m-> 2123\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'bias_act_plugin': [1/3] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/TH -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/THC -isystem /root/anaconda3/envs/stylegan3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' --use_fast_math --allow-unsupported-compiler -std=c++17 -c /root/.cache/torch_extensions/py39_cu121/bias_act_plugin/3cb576a0039689487cfba59279dd6d46-nvidia-geforce-rtx-4080-laptop-gpu/bias_act.cu -o bias_act.cuda.o \n\u001b[31mFAILED: \u001b[0mbias_act.cuda.o \n/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/TH -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/THC -isystem /root/anaconda3/envs/stylegan3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' --use_fast_math --allow-unsupported-compiler -std=c++17 -c /root/.cache/torch_extensions/py39_cu121/bias_act_plugin/3cb576a0039689487cfba59279dd6d46-nvidia-geforce-rtx-4080-laptop-gpu/bias_act.cu -o bias_act.cuda.o \nnvcc fatal   : Unsupported gpu architecture 'compute_89'\n[2/3] c++ -MMD -MF bias_act.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/TH -isystem /root/anaconda3/envs/stylegan3/lib/python3.9/site-packages/torch/include/THC -isystem /root/anaconda3/envs/stylegan3/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /root/.cache/torch_extensions/py39_cu121/bias_act_plugin/3cb576a0039689487cfba59279dd6d46-nvidia-geforce-rtx-4080-laptop-gpu/bias_act.cpp -o bias_act.o \nninja: build stopped: subcommand failed.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Define path to your dataset\n",
        "data_dir = 'Custom_Datatset'\n",
        "image_paths = []\n",
        "\n",
        "# List all subdirectories (categories)\n",
        "categories = os.listdir(data_dir)\n",
        "\n",
        "# Create a list to hold image paths\n",
        "for label, category in enumerate(categories):\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    for image_file in os.listdir(category_path):\n",
        "        image_path = os.path.join(category_path, image_file)\n",
        "        image_paths.append(image_path)\n",
        "\n",
        "# Define transformations for data preprocessing\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load the saved ResNet18 model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = models.resnet18(weights=None)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 25)  # 25 classes\n",
        "model.load_state_dict(torch.load('resnet18_finetuned.pth'))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Modify ResNet18 to extract features from the layer before the classification layer\n",
        "feature_extractor = nn.Sequential(*list(model.children())[:-1])  # Remove the last layer (fc layer)\n",
        "feature_extractor = feature_extractor.to(device)\n",
        "\n",
        "# Function to extract features using the modified ResNet18\n",
        "def extract_features(feature_extractor, image_paths, transform):\n",
        "    features = []\n",
        "    for image_path in image_paths:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            feature = feature_extractor(image)\n",
        "            feature = feature.view(feature.size(0), -1)  # Flatten the feature map\n",
        "            feature = nn.functional.adaptive_avg_pool1d(feature.unsqueeze(0), 256).squeeze(0)  # Adjust the feature dimension to 256\n",
        "        features.append(feature.cpu().numpy().flatten())  # Flatten the features to 1D\n",
        "    return features\n",
        "\n",
        "# Extract features\n",
        "resnet_features = extract_features(feature_extractor, image_paths, data_transforms)\n",
        "\n",
        "# Generate random latent vectors (simulate StyleGAN3 latent vectors)\n",
        "stylegan_latent_vectors = np.random.randn(len(image_paths), 256)\n",
        "\n",
        "# Concatenate ResNet18 features and StyleGAN3 latent vectors\n",
        "# Adjusting the size to 512 as expected by StyleGAN3\n",
        "combined_features = [np.concatenate((resnet_feat, stylegan_latent), axis=0) for resnet_feat, stylegan_latent in zip(resnet_features, stylegan_latent_vectors)]\n",
        "\n",
        "# Function to perform linear interpolation\n",
        "def linear_interpolation(features, alpha=0.5):\n",
        "    interpolated_features = []\n",
        "    for i in range(len(features) - 1):\n",
        "        interp_feat = alpha * features[i] + (1 - alpha) * features[i + 1]\n",
        "        interpolated_features.append(interp_feat)\n",
        "    return interpolated_features\n",
        "\n",
        "# Perform linear interpolation on enhanced features\n",
        "interpolated_features = linear_interpolation(combined_features)\n",
        "\n",
        "# Load StyleGAN3 model\n",
        "with open('~/training-runs/00064-stylegan3-r-Custom_dataset_sgan-gpus1-batch32-gamma2/network-snapshot-000004.pkl', 'rb') as f:\n",
        "    G = pickle.load(f)['G_ema'].cuda()  # torch.nn.Module\n",
        "\n",
        "# Function to generate images using StyleGAN3\n",
        "def generate_enhanced_images(features):\n",
        "    enhanced_images = []\n",
        "    for feature in features:\n",
        "        stylegan_latent = torch.tensor(feature[:512], dtype=torch.float32).unsqueeze(0).cuda()  # Ensure the latent vector is in the correct format\n",
        "        img = G(stylegan_latent, None)  # Generate image\n",
        "        img = (img.clamp(-1, 1) + 1) / 2 * 255  # Convert to [0, 255] range\n",
        "        img = img.permute(0, 2, 3, 1).cpu().numpy().astype(np.uint8)  # Convert to HWC format and numpy array\n",
        "        enhanced_images.append(Image.fromarray(img[0]))\n",
        "    return enhanced_images\n",
        "\n",
        "# Generate enhanced images\n",
        "enhanced_images = generate_enhanced_images(interpolated_features)\n",
        "\n",
        "# Save generated images to disk\n",
        "output_dir = 'Enhanced_Images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for i, img in enumerate(enhanced_images):\n",
        "    img.save(os.path.join(output_dir, f'enhanced_image_{i}.png'))\n",
        "\n",
        "print(\"Enhanced images have been generated and saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "----------\n",
            " Loss: 3.2484 Acc: 0.0579\n",
            "Epoch 2/100\n",
            "----------\n",
            " Loss: 3.1623 Acc: 0.0814\n",
            "Epoch 3/100\n",
            "----------\n",
            " Loss: 3.0985 Acc: 0.1141\n",
            "Epoch 4/100\n",
            "----------\n",
            " Loss: 3.0447 Acc: 0.1426\n",
            "Epoch 5/100\n",
            "----------\n",
            " Loss: 2.9886 Acc: 0.1644\n",
            "Epoch 6/100\n",
            "----------\n",
            " Loss: 2.9298 Acc: 0.1820\n",
            "Epoch 7/100\n",
            "----------\n",
            " Loss: 2.8709 Acc: 0.2064\n",
            "Epoch 8/100\n",
            "----------\n",
            " Loss: 2.8217 Acc: 0.2232\n",
            "Epoch 9/100\n",
            "----------\n",
            " Loss: 2.7740 Acc: 0.2290\n",
            "Epoch 10/100\n",
            "----------\n",
            " Loss: 2.7064 Acc: 0.2810\n",
            "Epoch 11/100\n",
            "----------\n",
            " Loss: 2.6564 Acc: 0.2718\n",
            "Epoch 12/100\n",
            "----------\n",
            " Loss: 2.5983 Acc: 0.2953\n",
            "Epoch 13/100\n",
            "----------\n",
            " Loss: 2.5579 Acc: 0.2852\n",
            "Epoch 14/100\n",
            "----------\n",
            " Loss: 2.4924 Acc: 0.3205\n",
            "Epoch 15/100\n",
            "----------\n",
            " Loss: 2.4337 Acc: 0.3482\n",
            "Epoch 16/100\n",
            "----------\n",
            " Loss: 2.3831 Acc: 0.3582\n",
            "Epoch 17/100\n",
            "----------\n",
            " Loss: 2.3263 Acc: 0.3691\n",
            "Epoch 18/100\n",
            "----------\n",
            " Loss: 2.2787 Acc: 0.3851\n",
            "Epoch 19/100\n",
            "----------\n",
            " Loss: 2.2167 Acc: 0.4077\n",
            "Epoch 20/100\n",
            "----------\n",
            " Loss: 2.1805 Acc: 0.4262\n",
            "Epoch 21/100\n",
            "----------\n",
            " Loss: 2.1264 Acc: 0.4262\n",
            "Epoch 22/100\n",
            "----------\n",
            " Loss: 2.0828 Acc: 0.4379\n",
            "Epoch 23/100\n",
            "----------\n",
            " Loss: 2.0223 Acc: 0.4564\n",
            "Epoch 24/100\n",
            "----------\n",
            " Loss: 1.9759 Acc: 0.4782\n",
            "Epoch 25/100\n",
            "----------\n",
            " Loss: 1.9288 Acc: 0.4933\n",
            "Epoch 26/100\n",
            "----------\n",
            " Loss: 1.8770 Acc: 0.4899\n",
            "Epoch 27/100\n",
            "----------\n",
            " Loss: 1.8170 Acc: 0.5143\n",
            "Epoch 28/100\n",
            "----------\n",
            " Loss: 1.7387 Acc: 0.5394\n",
            "Epoch 29/100\n",
            "----------\n",
            " Loss: 1.6947 Acc: 0.5713\n",
            "Epoch 30/100\n",
            "----------\n",
            " Loss: 1.6577 Acc: 0.5730\n",
            "Epoch 31/100\n",
            "----------\n",
            " Loss: 1.6133 Acc: 0.5973\n",
            "Epoch 32/100\n",
            "----------\n",
            " Loss: 1.5590 Acc: 0.6023\n",
            "Epoch 33/100\n",
            "----------\n",
            " Loss: 1.4878 Acc: 0.6284\n",
            "Epoch 34/100\n",
            "----------\n",
            " Loss: 1.4550 Acc: 0.6275\n",
            "Epoch 35/100\n",
            "----------\n",
            " Loss: 1.3739 Acc: 0.6753\n",
            "Epoch 36/100\n",
            "----------\n",
            " Loss: 1.3308 Acc: 0.6753\n",
            "Epoch 37/100\n",
            "----------\n",
            " Loss: 1.3002 Acc: 0.7097\n",
            "Epoch 38/100\n",
            "----------\n",
            " Loss: 1.2146 Acc: 0.7164\n",
            "Epoch 39/100\n",
            "----------\n",
            " Loss: 1.1605 Acc: 0.7525\n",
            "Epoch 40/100\n",
            "----------\n",
            " Loss: 1.1307 Acc: 0.7341\n",
            "Epoch 41/100\n",
            "----------\n",
            " Loss: 1.0684 Acc: 0.7760\n",
            "Epoch 42/100\n",
            "----------\n",
            " Loss: 1.0019 Acc: 0.7911\n",
            "Epoch 43/100\n",
            "----------\n",
            " Loss: 0.9314 Acc: 0.8230\n",
            "Epoch 44/100\n",
            "----------\n",
            " Loss: 0.8693 Acc: 0.8356\n",
            "Epoch 45/100\n",
            "----------\n",
            " Loss: 0.8268 Acc: 0.8574\n",
            "Epoch 46/100\n",
            "----------\n",
            " Loss: 0.7774 Acc: 0.8557\n",
            "Epoch 47/100\n",
            "----------\n",
            " Loss: 0.7676 Acc: 0.8649\n",
            "Epoch 48/100\n",
            "----------\n",
            " Loss: 0.7295 Acc: 0.8674\n",
            "Epoch 49/100\n",
            "----------\n",
            " Loss: 0.6772 Acc: 0.8909\n",
            "Epoch 50/100\n",
            "----------\n",
            " Loss: 0.6781 Acc: 0.8909\n",
            "Epoch 51/100\n",
            "----------\n",
            " Loss: 0.5800 Acc: 0.9169\n",
            "Epoch 52/100\n",
            "----------\n",
            " Loss: 0.5235 Acc: 0.9270\n",
            "Epoch 53/100\n",
            "----------\n",
            " Loss: 0.4963 Acc: 0.9396\n",
            "Epoch 54/100\n",
            "----------\n",
            " Loss: 0.4581 Acc: 0.9430\n",
            "Epoch 55/100\n",
            "----------\n",
            " Loss: 0.4391 Acc: 0.9446\n",
            "Epoch 56/100\n",
            "----------\n",
            " Loss: 0.4035 Acc: 0.9581\n",
            "Epoch 57/100\n",
            "----------\n",
            " Loss: 0.4295 Acc: 0.9388\n",
            "Epoch 58/100\n",
            "----------\n",
            " Loss: 0.3618 Acc: 0.9606\n",
            "Epoch 59/100\n",
            "----------\n",
            " Loss: 0.3343 Acc: 0.9614\n",
            "Epoch 60/100\n",
            "----------\n",
            " Loss: 0.2993 Acc: 0.9614\n",
            "Epoch 61/100\n",
            "----------\n",
            " Loss: 0.2812 Acc: 0.9732\n",
            "Epoch 62/100\n",
            "----------\n",
            " Loss: 0.2854 Acc: 0.9648\n",
            "Epoch 63/100\n",
            "----------\n",
            " Loss: 0.2523 Acc: 0.9690\n",
            "Epoch 64/100\n",
            "----------\n",
            " Loss: 0.2372 Acc: 0.9664\n",
            "Epoch 65/100\n",
            "----------\n",
            " Loss: 0.2260 Acc: 0.9782\n",
            "Epoch 66/100\n",
            "----------\n",
            " Loss: 0.2179 Acc: 0.9757\n",
            "Epoch 67/100\n",
            "----------\n",
            " Loss: 0.1898 Acc: 0.9782\n",
            "Epoch 68/100\n",
            "----------\n",
            " Loss: 0.1826 Acc: 0.9732\n",
            "Epoch 69/100\n",
            "----------\n",
            " Loss: 0.1887 Acc: 0.9748\n",
            "Epoch 70/100\n",
            "----------\n",
            " Loss: 0.1797 Acc: 0.9757\n",
            "Epoch 71/100\n",
            "----------\n",
            " Loss: 0.1598 Acc: 0.9748\n",
            "Epoch 72/100\n",
            "----------\n",
            " Loss: 0.1662 Acc: 0.9723\n",
            "Epoch 73/100\n",
            "----------\n",
            " Loss: 0.1565 Acc: 0.9757\n",
            "Epoch 74/100\n",
            "----------\n",
            " Loss: 0.1448 Acc: 0.9765\n",
            "Epoch 75/100\n",
            "----------\n",
            " Loss: 0.1340 Acc: 0.9732\n",
            "Epoch 76/100\n",
            "----------\n",
            " Loss: 0.1196 Acc: 0.9815\n",
            "Epoch 77/100\n",
            "----------\n",
            " Loss: 0.1211 Acc: 0.9740\n",
            "Epoch 78/100\n",
            "----------\n",
            " Loss: 0.1119 Acc: 0.9748\n",
            "Epoch 79/100\n",
            "----------\n",
            " Loss: 0.1181 Acc: 0.9748\n",
            "Epoch 80/100\n",
            "----------\n",
            " Loss: 0.1143 Acc: 0.9773\n",
            "Epoch 81/100\n",
            "----------\n",
            " Loss: 0.1089 Acc: 0.9807\n",
            "Epoch 82/100\n",
            "----------\n",
            " Loss: 0.1037 Acc: 0.9757\n",
            "Epoch 83/100\n",
            "----------\n",
            " Loss: 0.1066 Acc: 0.9723\n",
            "Epoch 84/100\n",
            "----------\n",
            " Loss: 0.1058 Acc: 0.9748\n",
            "Epoch 85/100\n",
            "----------\n",
            " Loss: 0.1006 Acc: 0.9757\n",
            "Epoch 86/100\n",
            "----------\n",
            " Loss: 0.0891 Acc: 0.9773\n",
            "Epoch 87/100\n",
            "----------\n",
            " Loss: 0.0908 Acc: 0.9748\n",
            "Epoch 88/100\n",
            "----------\n",
            " Loss: 0.0872 Acc: 0.9773\n",
            "Epoch 89/100\n",
            "----------\n",
            " Loss: 0.0868 Acc: 0.9773\n",
            "Epoch 90/100\n",
            "----------\n",
            " Loss: 0.0882 Acc: 0.9765\n",
            "Epoch 91/100\n",
            "----------\n",
            " Loss: 0.0803 Acc: 0.9773\n",
            "Epoch 92/100\n",
            "----------\n",
            " Loss: 0.0842 Acc: 0.9757\n",
            "Epoch 93/100\n",
            "----------\n",
            " Loss: 0.0827 Acc: 0.9723\n",
            "Epoch 94/100\n",
            "----------\n",
            " Loss: 0.0780 Acc: 0.9799\n",
            "Epoch 95/100\n",
            "----------\n",
            " Loss: 0.0866 Acc: 0.9740\n",
            "Epoch 96/100\n",
            "----------\n",
            " Loss: 0.1061 Acc: 0.9732\n",
            "Epoch 97/100\n",
            "----------\n",
            " Loss: 0.1016 Acc: 0.9782\n",
            "Epoch 98/100\n",
            "----------\n",
            " Loss: 0.0950 Acc: 0.9748\n",
            "Epoch 99/100\n",
            "----------\n",
            " Loss: 0.0854 Acc: 0.9757\n",
            "Epoch 100/100\n",
            "----------\n",
            " Loss: 0.0774 Acc: 0.9782\n",
            "Classification Report on Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Shoe       0.22      0.31      0.26        13\n",
            "     Sneaker       0.41      0.50      0.45        14\n",
            "      Sandal       0.75      0.50      0.60        12\n",
            "         Hat       0.53      0.73      0.62        11\n",
            "         Cap       1.00      0.25      0.40         8\n",
            "  Sunglasses       0.14      0.10      0.12        10\n",
            "  Headphones       0.53      0.42      0.47        19\n",
            "     Perfume       0.37      0.62      0.47        16\n",
            "  Wristwatch       0.33      0.42      0.37        12\n",
            "       Glass       0.33      0.33      0.33        12\n",
            "         Bag       0.00      0.00      0.00         9\n",
            "     Handbag       0.47      0.54      0.50        13\n",
            "    Suitcase       0.20      0.44      0.28         9\n",
            "      Bottle       0.50      0.09      0.15        11\n",
            "         Cup       0.33      0.29      0.31        14\n",
            "Water Bottle       0.07      0.08      0.08        12\n",
            "         Can       0.50      0.17      0.25        12\n",
            "         Jar       0.38      0.64      0.47        14\n",
            "        Vase       0.67      0.67      0.67         9\n",
            "       Chair       0.31      0.83      0.45         6\n",
            "Office Chair       0.75      0.27      0.40        11\n",
            "       Couch       0.67      0.47      0.55        17\n",
            "     Baggage       0.14      0.11      0.12         9\n",
            "         Car       0.00      0.00      0.00        13\n",
            "         Toy       0.50      0.62      0.55        13\n",
            "\n",
            "    accuracy                           0.38       299\n",
            "   macro avg       0.40      0.38      0.35       299\n",
            "weighted avg       0.41      0.38      0.37       299\n",
            "\n",
            "Classification Report on Testing Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Shoe       0.22      0.31      0.26        13\n",
            "     Sneaker       0.41      0.50      0.45        14\n",
            "      Sandal       0.75      0.50      0.60        12\n",
            "         Hat       0.53      0.73      0.62        11\n",
            "         Cap       1.00      0.25      0.40         8\n",
            "  Sunglasses       0.14      0.10      0.12        10\n",
            "  Headphones       0.53      0.42      0.47        19\n",
            "     Perfume       0.37      0.62      0.47        16\n",
            "  Wristwatch       0.33      0.42      0.37        12\n",
            "       Glass       0.33      0.33      0.33        12\n",
            "         Bag       0.00      0.00      0.00         9\n",
            "     Handbag       0.47      0.54      0.50        13\n",
            "    Suitcase       0.20      0.44      0.28         9\n",
            "      Bottle       0.50      0.09      0.15        11\n",
            "         Cup       0.33      0.29      0.31        14\n",
            "Water Bottle       0.07      0.08      0.08        12\n",
            "         Can       0.50      0.17      0.25        12\n",
            "         Jar       0.38      0.64      0.47        14\n",
            "        Vase       0.67      0.67      0.67         9\n",
            "       Chair       0.31      0.83      0.45         6\n",
            "Office Chair       0.75      0.27      0.40        11\n",
            "       Couch       0.67      0.47      0.55        17\n",
            "     Baggage       0.14      0.11      0.12         9\n",
            "         Car       0.00      0.00      0.00        13\n",
            "         Toy       0.50      0.62      0.55        13\n",
            "\n",
            "    accuracy                           0.38       299\n",
            "   macro avg       0.40      0.38      0.35       299\n",
            "weighted avg       0.41      0.38      0.37       299\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#just an experiment\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import classification_report\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Define path to your dataset\n",
        "data_dir = 'Custom_Datatset'\n",
        "\n",
        "# List all subdirectories (categories)\n",
        "categories = os.listdir(data_dir)\n",
        "\n",
        "# Create a list to hold (image_path, category_label) tuples\n",
        "all_images = []\n",
        "\n",
        "# Loop through each category and collect image paths\n",
        "for label, category in enumerate(categories):\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    for image_file in os.listdir(category_path):\n",
        "        image_path = os.path.join(category_path, image_file)\n",
        "        all_images.append((image_path, label))\n",
        "\n",
        "# Shuffle the list of (image_path, category_label) tuples\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Define the dataset size and split ratio\n",
        "dataset_size = len(all_images)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "train_images = all_images[:train_size]\n",
        "test_images = all_images[train_size:]\n",
        "\n",
        "# Define transformations for data preprocessing\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = [(transforms.ToTensor()(Image.open(img)), label) for img, label in train_images]\n",
        "test_dataset = [(transforms.ToTensor()(Image.open(img)), label) for img, label in test_images]\n",
        "\n",
        "dataloaders = {\n",
        "    'train': DataLoader(train_dataset, batch_size=64, shuffle=True),\n",
        "    'test': DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "}\n",
        "\n",
        "# Define label_to_category mapping (same as before)\n",
        "label_to_category = {\n",
        "    0: 'Shoe',\n",
        "    1: 'Sneaker',\n",
        "    2: 'Sandal',\n",
        "    3: 'Hat',\n",
        "    4: 'Cap',\n",
        "    5: 'Sunglasses',\n",
        "    6: 'Headphones',\n",
        "    7: 'Perfume',\n",
        "    8: 'Wristwatch',\n",
        "    9: 'Glass',\n",
        "    10: 'Bag',\n",
        "    11: 'Handbag',\n",
        "    12: 'Suitcase',\n",
        "    13: 'Bottle',\n",
        "    14: 'Cup',\n",
        "    15: 'Water Bottle',\n",
        "    16: 'Can',\n",
        "    17: 'Jar',\n",
        "    18: 'Vase',\n",
        "    19: 'Chair',\n",
        "    20: 'Office Chair',\n",
        "    21: 'Couch',\n",
        "    22: 'Baggage',\n",
        "    23: 'Car',\n",
        "    24: 'Toy'\n",
        "}\n",
        "\n",
        "\n",
        "# Continue with model training, evaluation, and printing classification reports as before\n",
        "\n",
        "# Load pre-trained ResNet model\n",
        "model = models.resnet18(pretrained=False)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, len(label_to_category))\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / train_size\n",
        "        epoch_acc = running_corrects.double() / train_size\n",
        "\n",
        "        print(f' Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the model\n",
        "model = train_model(model, criterion, optimizer, num_epochs=100)\n",
        "torch.save(model.state_dict(), 'experiment_resnet18_finetuned.pth')\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['test']:\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "    return all_labels, all_preds\n",
        "\n",
        "# Evaluate on training set\n",
        "train_labels, train_preds = evaluate_model(model, dataloaders['train'])\n",
        "print('Classification Report on Training Set:')\n",
        "print(classification_report(train_labels, train_preds, target_names=label_to_category.values()))\n",
        "\n",
        "# Evaluate on testing set\n",
        "test_labels, test_preds = evaluate_model(model, dataloaders['test'])\n",
        "print('Classification Report on Testing Set:')\n",
        "print(classification_report(test_labels, test_preds, target_names=label_to_category.values()))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
